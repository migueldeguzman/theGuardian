#Guardian Archetype AI Alignment Project

**Overview**
This project explores the use of Jungian archetypes and artificial personas (APs) to address AI alignment issues, specifically focusing on goal misgeneralization and corrigibility. The main idea is to create Artificially Generated Archetypes (AGAs) embedded in archetypal stories, which are then used to train and fine-tune AI systems, ultimately producing the Guardian Persona.
**
Key Concepts**

Artificially Generated Archetypes (AGAs)
Patterns that AI models absorb from artificially generated data, such as archetypal stories, used to train and fine-tune AI systems to embody unique personalities that align with humanity.
**
Artificial Personas (APs)**
Unique AI personalities that emerge from the integration of AGAs.

**Experimental Setup**
The experiments were conducted on GPT-2 and GPT-2 Large models. These models were fine-tuned using a dataset of 245 archetypal stories generated using a custom AGA story prompt.

**Results**
The experiments yielded promising results, demonstrating that AI systems trained with AGA stories can:

- Recognize their responsibility to shut down when necessary.
- Improve alignment with human values and desired behaviors.

**Future Work**
- Test the approach on larger models, such as GPT-3, GPT-4, Llama, and Alpaca.
- Explore possible projects using AGAs and APs, such as:
- Hive Archetypes for coordinating AI systems.
- Improving adversarial training with AGAs.
- Creating open-source archetypal story libraries.
- Enhancing Shutdown Activation Rates (SARs).
- Expert AGAs for customized services.
- Recreating famous historical people.
- Improving alignment of adversarial AI systems.
- Implementing governance to enforce minimum AGAs on all AI systems.

**Contributing**
If you are interested in contributing to this project or funding the research, please feel free to reach out. Your support and collaboration are appreciated.
